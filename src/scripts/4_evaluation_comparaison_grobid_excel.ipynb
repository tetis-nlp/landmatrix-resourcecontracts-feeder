{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliothèques à installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install openpyxl\n",
    "!pip install unidecode fuzzywuzzy[speedup]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code pour trier les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "EXTRACTED_JSON = \"extracted_contract_info.json\"\n",
    "\n",
    "# === Load the JSON ===\n",
    "with open(EXTRACTED_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === Extract numeric part of ID for sorting ===\n",
    "def extract_numeric_id(entry):\n",
    "    id_str = entry.get(\"id\") or entry.get(\"file_name\", \"\")\n",
    "    id_str = id_str.replace(\".pdf\", \"\").strip().lower()\n",
    "    match = re.search(r'\\d+', id_str)\n",
    "    return int(match.group()) if match else float(\"inf\")  # sort non-numeric IDs last\n",
    "\n",
    "# === Sort entries by numeric ID ===\n",
    "sorted_data = sorted(data, key=extract_numeric_id)\n",
    "\n",
    "with open(\"sorted_by_numeric_id.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sorted_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Sorted numerically by ID and saved {len(sorted_data)} entries to 'sorted_by_numeric_id.json'\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation and comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from fuzzywuzzy import fuzz\n",
    "import unidecode\n",
    "\n",
    "\n",
    "EXTRACTED_JSON = \"sorted_by_numeric_id.json\"\n",
    "GROUND_TRUTH_XLSX = \"contracts_labelized_example.xlsx\"\n",
    "\n",
    "with open(EXTRACTED_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    extracted_data = json.load(f)\n",
    "\n",
    "extracted_df = pd.DataFrame(extracted_data)\n",
    "ground_truth_df = pd.read_excel(GROUND_TRUTH_XLSX)\n",
    "\n",
    "extracted_df[\"id\"] = extracted_df[\"id\"].astype(str).str.strip().str.lower()\n",
    "ground_truth_df[\"id\"] = ground_truth_df[\"id\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "extracted_df.rename(columns={\n",
    "    \"titre_contrat\": \"pred_titre_contrat\",\n",
    "    \"pays_cible\": \"pred_pays_cible\",\n",
    "    \"societe_exploitation\": \"pred_societe_exploitation\"\n",
    "}, inplace=True)\n",
    "\n",
    "merged_df = pd.merge(ground_truth_df, extracted_df, on=\"id\", how=\"inner\")\n",
    "print(f\"Found {len(merged_df)} matched rows\")\n",
    "\n",
    "if merged_df.empty:\n",
    "    print(\"No matching IDs found.\")\n",
    "    exit()\n",
    "\n",
    "def normalize_text(s):\n",
    "    if isinstance(s, str):\n",
    "        s = s.lower().strip()\n",
    "        s = unidecode.unidecode(s)  # remove accents\n",
    "        return s\n",
    "    elif isinstance(s, list):\n",
    "        return [normalize_text(i) for i in s if isinstance(i, str)]\n",
    "    return s\n",
    "\n",
    "for col in [\"titre_contrat\", \"pred_titre_contrat\", \"societe_exploitation\", \"pred_societe_exploitation\", \"pays_cible\", \"pred_pays_cible\"]:\n",
    "    merged_df[col] = merged_df[col].apply(normalize_text)\n",
    "\n",
    "\n",
    "def fuzzy_match(str1, str2, threshold=85):\n",
    "    if not isinstance(str1, str) or not isinstance(str2, str):\n",
    "        return False\n",
    "    score = fuzz.token_set_ratio(str1, str2)\n",
    "    return score >= threshold\n",
    "\n",
    "merged_df[\"titre_contrat_match\"] = merged_df.apply(\n",
    "    lambda row: fuzzy_match(row[\"titre_contrat\"], row[\"pred_titre_contrat\"]), axis=1\n",
    ")\n",
    "merged_df[\"societe_exploitation_match\"] = merged_df.apply(\n",
    "    lambda row: fuzzy_match(row[\"societe_exploitation\"], row[\"pred_societe_exploitation\"]), axis=1\n",
    ")\n",
    "\n",
    "titre_accuracy = merged_df[\"titre_contrat_match\"].mean()\n",
    "societe_accuracy = merged_df[\"societe_exploitation_match\"].mean()\n",
    "\n",
    "print(f\"Accuracy (titre_contrat) with fuzzy matching: {titre_accuracy:.2f}\")\n",
    "print(f\"Accuracy (societe_exploitation) with fuzzy matching: {societe_accuracy:.2f}\")\n",
    "\n",
    "country_map = {\n",
    "    \"republique d'afrique du sud\": \"afrique du sud\",\n",
    "    \"iles vierges britanniques\": \"british virgin island\",\n",
    "    \"british virgin island\": \"british virgin island\",\n",
    "    \"rdc\": \"republique du congo\",\n",
    "    \"republique du congo\": \"republique du congo\",\n",
    "    \n",
    "}\n",
    "\n",
    "def map_countries(lst):\n",
    "    if not isinstance(lst, list):\n",
    "        return []\n",
    "    return [country_map.get(c, c) for c in lst]\n",
    "\n",
    "def to_list(x):\n",
    "    if isinstance(x, str):\n",
    "        return [i.strip() for i in x.split(\",\") if i.strip()]\n",
    "    elif isinstance(x, list):\n",
    "        return [str(i).strip() for i in x if isinstance(i, str)]\n",
    "    return []\n",
    "\n",
    "merged_df[\"true_pays\"] = merged_df[\"pays_cible\"].apply(to_list).apply(normalize_text).apply(map_countries)\n",
    "merged_df[\"pred_pays\"] = merged_df[\"pred_pays_cible\"].apply(to_list).apply(normalize_text).apply(map_countries)\n",
    "\n",
    "valid_df = merged_df[\n",
    "    merged_df[\"true_pays\"].apply(bool) & merged_df[\"pred_pays\"].apply(bool)\n",
    "]\n",
    "\n",
    "if valid_df.empty:\n",
    "    print(\"\\nNo valid rows with non-empty 'pays_cible' and 'pred_pays_cible'.\")\n",
    "else:\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y_true = mlb.fit_transform(valid_df[\"true_pays\"])\n",
    "    y_pred = mlb.transform(valid_df[\"pred_pays\"])  \n",
    "\n",
    "    try:\n",
    "        report = classification_report(y_true, y_pred, target_names=mlb.classes_, zero_division=0)\n",
    "        print(\"\\nClassification Report for 'pays_cible':\")\n",
    "        print(report)\n",
    "    except ValueError as e:\n",
    "        print(\"\\nError generating classification report:\", str(e))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
